{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Workflows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fibsem import utils\n",
    "\n",
    "microscope, settings = utils.setup_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automated Quality Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# do contrast test polishing\n",
    "protocol = {\n",
    "    \"milling\": {\n",
    "        \"polish\": {\n",
    "            \"stages\": [{\n",
    "        \"application_file\": \"autolamella\",\n",
    "        \"cross_section\": \"CleaningCrossSection\",\n",
    "        \"hfw\": 40e-6,\n",
    "        \"height\": 6.0e-07,\n",
    "        \"width\": 6.0e-06,\n",
    "        \"depth\": 4.0e-07,\n",
    "        \"milling_current\": 6.0e-11,\n",
    "        \"milling_voltage\": 3.0e3,\n",
    "        \"type\": \"Rectangle\",\n",
    "        \"name\": \"AdaptivePolishing\",\n",
    "            }\n",
    "        ],\n",
    "        \"point\": {\n",
    "            \"x\": 0.0,\n",
    "            \"y\": 5e-6,}\n",
    "        }\n",
    "    },\n",
    "    \"options\": {\n",
    "        \"experimental\": {\n",
    "            \"adaptive_polishing\": {\n",
    "                \"threshold\": 100,\n",
    "                \"step_size\": 5e-6,\n",
    "                \"step_limit\": 10,\n",
    "                \"image_resolution\": [3072, 2188],\n",
    "                \"image_line_integration\": 20,\n",
    "                \"image_dwell_time\": 100e-9,\n",
    "            }\n",
    "\n",
    "    }\n",
    "}\n",
    "}\n",
    "\n",
    "from autolamella.workflows.experimental import adaptive_mill_polishing\n",
    "\n",
    "\n",
    "adaptive_mill_polishing(microscope, settings, protocol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State Management Refactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from autolamella.structures import AutoLamellaStage, Experiment, AutoLamellaProtocol\n",
    "from pprint import pprint\n",
    "\n",
    "EXP_PATH = \"/home/patrick/github/autolamella/autolamella/log/AutoLamella-2025-01-10-14-24/experiment.yaml\"\n",
    "PROTOCOL_PATH = \"/home/patrick/github/autolamella/autolamella/log/AutoLamella-2025-01-10-14-24/protocol.yaml\"\n",
    "exp = Experiment.load(EXP_PATH)\n",
    "pos = exp.positions[0]\n",
    "protocol = AutoLamellaProtocol.load(PROTOCOL_PATH)\n",
    "\n",
    "print(protocol.method.workflow)\n",
    "\n",
    "print(f\"Last Completed: {pos.last_completed}\")\n",
    "print(f\"Next: \", protocol.method.get_next(pos.workflow))\n",
    "print(f\"Previous: \", protocol.method.get_previous(pos.workflow))\n",
    "print(f\"Workflow: \", protocol.method.workflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoLamellaProtocol Class\n",
    "\n",
    "protocol:\n",
    "- name\n",
    "- method:\n",
    "- configuration:\n",
    "- options\n",
    "- supervision\n",
    "- milling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from autolamella.structures import AutoLamellaStage, Experiment, AutoLamellaProtocol\n",
    "import os\n",
    "import glob\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "BASE_PATH = \"/home/patrick/github/autolamella/autolamella/protocol/protocol-*-new.yaml\"\n",
    "\n",
    "# TODO: TRENCH MILLING METHOD\n",
    "\n",
    "filenames = glob.glob(BASE_PATH)\n",
    "pprint(filenames)\n",
    " \n",
    "\n",
    "PROTOCOL_PATH =  \"/home/patrick/github/autolamella/autolamella/protocol/protocol-waffle-new.yaml\"\n",
    "\n",
    "protocol = AutoLamellaProtocol.load(PROTOCOL_PATH)\n",
    "\n",
    "# pprint(protocol.to_dict()[\"name\"])\n",
    "\n",
    "# pprint()\n",
    "# from fibsem.milling import \n",
    "# protocol.milling\n",
    "\n",
    "pprint(protocol.tmp)\n",
    "# pprint(protocol.options)\n",
    "# print(protocol.supervision)\n",
    "# print(protocol.method.workflow)\n",
    "\n",
    "# from fibsem.structures import FibsemImage\n",
    "# from fibsem.milling.patterning.plotting import draw_milling_patterns\n",
    "\n",
    "# stages = protocol.milling[\"undercut\"]\n",
    "\n",
    "# image = FibsemImage.generate_blank_image(hfw=stages[0].milling.hfw)\n",
    "# draw_milling_patterns(image, stages)\n",
    "\n",
    "\n",
    "pprint(protocol.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autolamella.protocol.validation import validate_protocol\n",
    "from fibsem import utils\n",
    "protocol = validate_protocol(utils.load_protocol(protocol_path=PROTOCOL_PATH))\n",
    "\n",
    "protocol2 = AutoLamellaProtocol.from_dict(protocol)\n",
    "pprint(protocol2.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autolamella.structures import AutoLamellaMethod\n",
    "\n",
    "[m.name for m in AutoLamellaMethod]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Review Tools\n",
    "\n",
    "- Time estimatation for remaining\n",
    "- Display Images for each workflow stage\n",
    "- Generate a Report (pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from autolamella.structures import Lamella, AutoLamellaStage, Experiment, AutoLamellaProtocol, AutoLamellaMethod, get_completed_stages\n",
    "from pprint import pprint\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "from fibsem.structures import FibsemImage\n",
    "import glob\n",
    "import os\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "EXP_PATH = \"/home/patrick/github/autolamella/autolamella/log/AutoLamella-2025-01-10-14-24/experiment.yaml\"\n",
    "PROTOCOL_PATH = \"/home/patrick/github/autolamella/autolamella/log/AutoLamella-2025-01-10-14-24/protocol.yaml\"\n",
    "\n",
    "PATH = \"/home/patrick/data/monash-cryo-em/AutoLamella-Exports\" \n",
    "filenames = glob.glob(os.path.join(PATH, \"**/experiment.yaml\"), recursive=True)\n",
    "filenames.insert(0, EXP_PATH)\n",
    "\n",
    "\n",
    "# pprint(filenames)\n",
    "# EXP_PATH = filenames[0]\n",
    "\n",
    "\n",
    "exp = Experiment.load(EXP_PATH)\n",
    "pos = exp.positions[0]\n",
    "protocol = AutoLamellaProtocol.load(PROTOCOL_PATH)\n",
    "\n",
    "# print(protocol.method.workflow)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_workflow_snapshot(pos: Lamella, wf: AutoLamellaStage, target_size: int = 256) -> np.ndarray:\n",
    "    \"\"\"Get a snapshot of a workflow stage for a given position\"\"\"\n",
    "\n",
    "    if not isinstance(target_size, int):\n",
    "        target_size = int(target_size)\n",
    "\n",
    "    # get the final high res images\n",
    "    filenames = glob.glob(os.path.join(pos.path, f\"*{wf.name}*final_high_res*.tif*\"))\n",
    "    \n",
    "    if len(filenames) == 0:\n",
    "        print(f\"No images found for {pos.name} - {wf.name}\")\n",
    "        return None\n",
    "\n",
    "    # resize and stack the images for display\n",
    "    sarr = None\n",
    "    for fname in sorted(filenames):\n",
    "        img = FibsemImage.load(fname)\n",
    "        shape = img.data.shape\n",
    "        resize_shape = (int(shape[0] * (target_size / shape[1])), target_size)\n",
    "        arr = np.asarray(PIL.Image.fromarray(img.data).resize(resize_shape[::-1]))\n",
    "        \n",
    "        # stack\n",
    "        if sarr is None:\n",
    "            sarr = arr\n",
    "        else:\n",
    "            sarr = np.append(sarr, arr, axis=1)\n",
    "    return sarr\n",
    "\n",
    "def convert_figure_to_np_array(figure: plt.Figure) -> np.ndarray:\n",
    "    \"\"\"Convert a matplotlib figure to a numpy array\"\"\"\n",
    "    # Draw the figure\n",
    "    figure.canvas.draw()\n",
    "    # Get the RGBA buffer\n",
    "    buf = figure.canvas.buffer_rgba()\n",
    "    # Convert to numpy array\n",
    "    arr = np.asarray(buf)\n",
    "    plt.close()\n",
    "    return arr\n",
    "\n",
    "target_size = 1536 / 4\n",
    "\n",
    "for filename in filenames[1:2]:\n",
    "\n",
    "    print(f\"Experiment: {os.path.basename(filename)}\")\n",
    "    exp = Experiment.load(filename)\n",
    "\n",
    "    for i, pos in enumerate(exp.positions):\n",
    "        print(\"-\"*80)\n",
    "        print(pos.name, pos.path)\n",
    "\n",
    "        stages_completed = get_completed_stages(pos, method=protocol.method)\n",
    "\n",
    "        for wf in stages_completed:\n",
    "\n",
    "            # if not on same computer\n",
    "            if not os.path.exists(pos.path):\n",
    "                print(f\"Path does not exist: {pos.path}, remapping to experiment path\")\n",
    "                pos.path = os.path.join(exp.path, pos.name)\n",
    "\n",
    "            snapshot = get_workflow_snapshot(pos, wf, target_size=target_size)\n",
    "\n",
    "            if snapshot is None:\n",
    "                print(f\"Skipping {pos.name} - {wf.name}, no images found.\")\n",
    "                continue\n",
    "\n",
    "            cx1 = snapshot.shape[1] // 4\n",
    "            cx2 = snapshot.shape[1] // 2 + cx1\n",
    "            cy = snapshot.shape[0] // 2\n",
    "\n",
    "            fig = plt.figure()\n",
    "            plt.title(f\"Lamella {pos.name} - {pos.states[wf].completed}\")\n",
    "            plt.imshow(snapshot, cmap=\"gray\")\n",
    "            plt.plot([cx1, cx2], [cy, cy], \"y+\", ms=20)\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()\n",
    "\n",
    "            array = convert_figure_to_np_array(fig)\n",
    "            print(array.shape)\n",
    "\n",
    "            # save array using PIL\n",
    "            # img = PIL.Image.fromarray(array)\n",
    "            # img.save(f\"lamella_{pos.name}_{wf.name}.png\")\n",
    "\n",
    "            # break\n",
    "\n",
    "            # TODO: scalebar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review - Report Gen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from autolamella.structures import Lamella, AutoLamellaStage, Experiment, AutoLamellaProtocol, AutoLamellaMethod, get_completed_stages\n",
    "from pprint import pprint\n",
    "from autolamella.tools.data import calculate_statistics_dataframe\n",
    "\n",
    "import numpy as np\n",
    "from fibsem.structures import FibsemImage\n",
    "import glob\n",
    "import os\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "EXP_PATH = \"/home/patrick/github/autolamella/autolamella/log/AutoLamella-2025-01-10-14-24/experiment.yaml\"  # v.0.4.0\n",
    "# PROTOCOL_PATH = \"/home/patrick/github/autolamella/autolamella/log/AutoLamella-2025-01-10-14-24/protocol.yaml\"\n",
    "\n",
    "PATH = \"/home/patrick/data/monash-cryo-em/AutoLamella-Exports\" # 0.3.4+\n",
    "filenames = glob.glob(os.path.join(PATH, \"**/experiment.yaml\"), recursive=True)\n",
    "filenames.insert(0, EXP_PATH)\n",
    "\n",
    "pprint(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = calculate_statistics_dataframe(os.path.dirname(filenames[2]), encoding=\"cp1252\")\n",
    "\n",
    "\n",
    "df_experiment, df_history, df_beam_shift, df_steps, df_stage, df_det, df_click, df_milling =  dfs\n",
    "\n",
    "\n",
    "display(df_history)\n",
    "display(df_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.lib import colors\n",
    "from reportlab.lib.pagesizes import letter, A4\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image, Table, TableStyle, PageBreak\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.units import inch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import io\n",
    "\n",
    "class PDFReportGenerator:\n",
    "    def __init__(self, output_filename: str):\n",
    "        self.output_filename = output_filename\n",
    "        self.doc = SimpleDocTemplate(\n",
    "            output_filename,\n",
    "            pagesize=A4,\n",
    "            rightMargin=72,\n",
    "            leftMargin=72,\n",
    "            topMargin=72,\n",
    "            bottomMargin=72\n",
    "        )\n",
    "        self.styles = getSampleStyleSheet()\n",
    "        self.story = []\n",
    "\n",
    "        # Create custom styles\n",
    "        self.styles.add(ParagraphStyle(\n",
    "            'CustomTitle',\n",
    "            parent=self.styles['Heading1'],\n",
    "            fontSize=24,\n",
    "            spaceAfter=30,\n",
    "            alignment=1  # Center alignment\n",
    "        ))\n",
    "        \n",
    "        self.styles.add(ParagraphStyle(\n",
    "            'Subtitle',\n",
    "            parent=self.styles['Normal'],\n",
    "            fontSize=14,\n",
    "            textColor=colors.grey,\n",
    "            alignment=1,\n",
    "            spaceAfter=20\n",
    "        ))\n",
    "\n",
    "    def add_title(self, title, subtitle=None):\n",
    "        \"\"\"Add a title and optional subtitle to the document\"\"\"\n",
    "        self.story.append(Paragraph(title, self.styles['CustomTitle']))\n",
    "        if subtitle:\n",
    "            self.story.append(Paragraph(subtitle, self.styles['Subtitle']))\n",
    "        self.story.append(Spacer(1, 20))\n",
    "\n",
    "    def add_heading(self, text, level=2):\n",
    "        \"\"\"Add a heading with specified level\"\"\"\n",
    "        style = self.styles[f'Heading{level}']\n",
    "        self.story.append(Paragraph(text, style))\n",
    "        self.story.append(Spacer(1, 12))\n",
    "\n",
    "    def add_paragraph(self, text):\n",
    "        \"\"\"Add a paragraph of text\"\"\"\n",
    "        self.story.append(Paragraph(text, self.styles['Normal']))\n",
    "        self.story.append(Spacer(1, 12))\n",
    "\n",
    "    def add_page_break(self):\n",
    "        \"\"\"Add a page break\"\"\"\n",
    "        self.story.append(PageBreak())\n",
    "\n",
    "    def add_image(self, path: str, width=6*inch, height=4*inch):\n",
    "        \"\"\"Add an image to the PDF\"\"\"\n",
    "        img = Image(path, width=width, height=height)\n",
    "        self.story.append(img)\n",
    "        self.story.append(Spacer(1, 20))\n",
    "\n",
    "    def add_dataframe(self, df, title=None, includes_totals=False):\n",
    "        \"\"\"Add a pandas DataFrame as a table\"\"\"\n",
    "        if title:\n",
    "            self.add_heading(title, 3)\n",
    "        \n",
    "        # Convert DataFrame to list of lists\n",
    "        data = [df.columns.tolist()] + df.values.tolist()\n",
    "        \n",
    "        # Create table style\n",
    "        style = TableStyle([\n",
    "            ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#2F4F4F')),\n",
    "            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n",
    "            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "            ('FONTSIZE', (0, 0), (-1, 0), 12),\n",
    "            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\n",
    "            ('BACKGROUND', (0, 1), (-1, -1), colors.white),\n",
    "            ('TEXTCOLOR', (0, 1), (-1, -1), colors.black),\n",
    "            ('FONTNAME', (0, 1), (-1, -1), 'Helvetica'),\n",
    "            ('FONTSIZE', (0, 1), (-1, -1), 10),\n",
    "            ('GRID', (0, 0), (-1, -1), 1, colors.black),\n",
    "            ('ROWBACKGROUNDS', (0, 1), (-1, -1), [colors.whitesmoke, colors.white])\n",
    "        ])\n",
    "        \n",
    "        if includes_totals:\n",
    "            style.add('BACKGROUND', (0, -1), (-1, -1), colors.HexColor('#E8E8E8'))\n",
    "            style.add('FONTNAME', (0, -1), (-1, -1), 'Helvetica-Bold')\n",
    "        \n",
    "        table = Table(data)\n",
    "        table.setStyle(style)\n",
    "        self.story.append(table)\n",
    "        self.story.append(Spacer(1, 20))\n",
    "\n",
    "    def add_plot(self, plot_function, title=None, *args, **kwargs):\n",
    "        \"\"\"Add a matplotlib plot\n",
    "        plot_function should be a function that creates and returns a matplotlib figure\n",
    "        \"\"\"\n",
    "        if title:\n",
    "            self.add_heading(title, 3)\n",
    "        \n",
    "        # Create plot and save to bytes buffer\n",
    "        fig = plot_function(*args, **kwargs)\n",
    "        img_buffer = io.BytesIO()\n",
    "        fig.savefig(img_buffer, format='png', bbox_inches='tight', dpi=300)\n",
    "        img_buffer.seek(0)\n",
    "        \n",
    "        # Add plot to story\n",
    "        img = Image(img_buffer, width=6*inch, height=4*inch)\n",
    "        self.story.append(img)\n",
    "        self.story.append(Spacer(1, 20))\n",
    "        plt.close(fig)\n",
    "\n",
    "    def add_mpl_figure(self, fig):\n",
    "        fig.savefig('temp.png', format='png', bbox_inches='tight', dpi=300)\n",
    "        self.story.append(Image('temp.png'))\n",
    "\n",
    "    def add_plotly_figure(self, fig, title=None, width=6.5*inch, height=4*inch):\n",
    "        \"\"\"Add a Plotly figure to the PDF\"\"\"\n",
    "        if title:\n",
    "            self.add_heading(title, 3)\n",
    "        \n",
    "        # Convert Plotly figure to static image\n",
    "        img_bytes = fig.to_image(format=\"png\", width=900, height=500, scale=2)\n",
    "        \n",
    "        # Create BytesIO object\n",
    "        img_buffer = io.BytesIO(img_bytes)\n",
    "        \n",
    "        # Add image to story\n",
    "        img = Image(img_buffer, width=width, height=height)\n",
    "        self.story.append(img)\n",
    "        self.story.append(Spacer(1, 20))\n",
    "\n",
    "    def generate(self):\n",
    "        \"\"\"Generate the PDF document\"\"\"\n",
    "        self.doc.build(self.story)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from typing import Tuple, Dict\n",
    "import numpy as np\n",
    "from autolamella.structures import AutoLamellaStage\n",
    "from fibsem.milling.patterning.plotting import draw_milling_patterns\n",
    "from fibsem.milling import get_milling_stages\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from fibsem.structures import FibsemImage\n",
    "from autolamella.protocol.validation import convert_old_milling_protocol_to_new_protocol, MILL_POLISHING_KEY, MILL_ROUGH_KEY, MICROEXPANSION_KEY, FIDUCIAL_KEY\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "def get_lamella_figures(p: Lamella, exp_path: str) -> dict:\n",
    "\n",
    "    # convert old lamella protocol to new style\n",
    "    if \"lamella\" in p.protocol or \"MillRoughCut\" in p.protocol:\n",
    "        print(f\"Converting protocol for {p.name}\")\n",
    "        nprotocol = convert_old_milling_protocol_to_new_protocol(p.protocol)\n",
    "        if \"MillRoughCut\" in nprotocol:\n",
    "            nprotocol[MILL_ROUGH_KEY] = nprotocol.pop(\"MillRoughCut\")\n",
    "\n",
    "        if \"MillPolishingCut\" in nprotocol:\n",
    "            nprotocol[MILL_POLISHING_KEY] = nprotocol.pop(\"MillPolishingCut\")\n",
    "\n",
    "        if \"lamella\" in nprotocol:\n",
    "            del nprotocol[\"lamella\"]\n",
    "\n",
    "        p.protocol = deepcopy(nprotocol)\n",
    "\n",
    "    p.path = os.path.join(exp_path, p.name)\n",
    "\n",
    "    def get_lamella_milling_plots(p: Lamella) -> plt.Figure:\n",
    "\n",
    "        # DRAW MILLING PATTERNS\n",
    "        milling_workflows = [MILL_ROUGH_KEY, MILL_POLISHING_KEY, MICROEXPANSION_KEY, FIDUCIAL_KEY]\n",
    "        milling_stages = []\n",
    "        for mw in milling_workflows:\n",
    "            milling_stages.extend(get_milling_stages(key=mw, protocol=p.protocol))\n",
    "\n",
    "        filenames = sorted(glob.glob(os.path.join(p.path, \"ref_MillPolishing*_final_high_res_ib.tif*\")))\n",
    "\n",
    "        if len(filenames) == 0:\n",
    "            print(f\"No images found for {p.name}\")\n",
    "            # continue\n",
    "            return None\n",
    "\n",
    "        # sem_image = FibsemImage.load(filenames[0])\n",
    "        fib_image = FibsemImage.load(filenames[0])\n",
    "\n",
    "        fig, ax = draw_milling_patterns(fib_image, milling_stages, title=f\"{p.name}\")\n",
    "\n",
    "        return fig\n",
    "\n",
    "    fig_milling = get_lamella_milling_plots(p)\n",
    "\n",
    "\n",
    "    filenames = sorted(glob.glob(os.path.join(p.path, \"ref_MillPolishing*_final_high_res*.tif*\")))\n",
    "    sem_image = FibsemImage.load(filenames[0])\n",
    "    fib_image = FibsemImage.load(filenames[1])\n",
    "\n",
    "    fig_images, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax[0].imshow(sem_image.data, cmap=\"gray\")\n",
    "    ax[1].imshow(fib_image.data, cmap=\"gray\")\n",
    "    # plt.show()\n",
    "\n",
    "    FIGURES = {\"milling\": deepcopy(fig_milling), \"images\": deepcopy(fig_images)}\n",
    "    return FIGURES\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_multi_gantt(df: pd.DataFrame, color_by='piece_id', barmode='group') -> go.Figure:\n",
    "    \"\"\"\n",
    "    Create a Gantt chart for multiple pieces/processes\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame with columns [piece_id, step, timestamp, end_time]\n",
    "    - color_by: Column to use for color coding ('piece_id' or 'step')\n",
    "    - barmode: 'group' or 'overlay' for how bars should be displayed\n",
    "    \"\"\"\n",
    "    fig = px.timeline(\n",
    "        df, \n",
    "        x_start='start_time',\n",
    "        x_end='end_time',\n",
    "        y='step',\n",
    "        color=color_by,\n",
    "        # title='Multi-Process Timeline',\n",
    "        # hover_data=['duration']  # Uncomment to show duration in hover\n",
    "    )\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title_x=0.5,\n",
    "        xaxis_title='Time',\n",
    "        yaxis_title='Workflow Step',\n",
    "        height=400,\n",
    "        barmode=barmode,  # 'group' or 'overlay'\n",
    "        yaxis={'categoryorder': 'array', \n",
    "               'categoryarray': df['step'].unique()},\n",
    "        showlegend=True,\n",
    "        # legend_title_text='Piece ID'\n",
    "    )\n",
    "\n",
    "    # Reverse y-axis so first step is at top\n",
    "    fig.update_yaxes(autorange=\"reversed\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def generate_workflow_steps_timeline(df: pd.DataFrame) -> Dict[str, go.Figure]:\n",
    "\n",
    "    timezone = datetime.now().astimezone().tzinfo\n",
    "\n",
    "    df[\"start_time\"] = pd.to_datetime(df[\"timestamp\"], unit=\"s\").dt.tz_localize(\"UTC\").dt.tz_convert(timezone)\n",
    "    df['end_time'] = df['start_time'] + pd.to_timedelta(df['duration'], unit='s')\n",
    "\n",
    "    # # drop step in Created, Finished\n",
    "    df = df[~df[\"stage\"].isin([\"Created\", \"PreSetupLamella\", \"SetupLamella\", \"PositionReady\", \"Finished\"])]\n",
    "    # drop step in [STARTED, FINISHED, NULL_END]\n",
    "    df = df[~df[\"step\"].isin([\"STARTED\", \"FINISHED\", \"NULL_END\"])]\n",
    "\n",
    "    WORKFLOW_STEPS_FIGURES = {}\n",
    "\n",
    "    for stage_name in df[\"stage\"].unique():\n",
    "        df1 = df[df[\"stage\"] == stage_name]\n",
    "        fig = plot_multi_gantt(df1, color_by='step', barmode='overlay')\n",
    "        \n",
    "        WORKFLOW_STEPS_FIGURES[stage_name] = fig\n",
    "\n",
    "    return WORKFLOW_STEPS_FIGURES    \n",
    "\n",
    "\n",
    "def generate_workflow_timeline(df: pd.DataFrame) -> go.Figure:\n",
    "\n",
    "    # drop rows with duration over 1 day\n",
    "    df = df[df[\"duration\"] < 86400]\n",
    "\n",
    "    timezone = datetime.now().astimezone().tzinfo\n",
    "    df[\"start_time\"] = pd.to_datetime(df[\"start\"], unit=\"s\").dt.tz_localize(\"UTC\").dt.tz_convert(timezone)\n",
    "    df[\"end_time\"] = pd.to_datetime(df[\"end\"], unit=\"s\").dt.tz_localize(\"UTC\").dt.tz_convert(timezone)\n",
    "\n",
    "    df.rename({\"stage\": \"step\"}, axis=1, inplace=True)\n",
    "\n",
    "    # drop step in Created, Finished\n",
    "    df = df[~df[\"step\"].isin([\"Created\", \"Finished\"])]\n",
    "\n",
    "    fig = plot_multi_gantt(df, color_by='step', barmode='overlay')\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def generate_report_timeline(df: pd.DataFrame):\n",
    "    # plot time series with x= step_n and y = timestamp with step  as hover text\n",
    "    df.dropna(inplace=True)\n",
    "    df.duration = df.duration.astype(int)\n",
    "\n",
    "    # convert timestamp to datetime, aus timezone \n",
    "    df.timestamp = pd.to_datetime(df.timestamp, unit=\"s\")\n",
    "\n",
    "    # convert timestamp to current timezone\n",
    "     # get current timezone?\n",
    "    timezone = datetime.now().astimezone().tzinfo\n",
    "    df.timestamp = df.timestamp.dt.tz_localize(\"UTC\").dt.tz_convert(timezone)\n",
    "\n",
    "    df.rename(columns={\"stage\": \"Workflow\"}, inplace=True)\n",
    "\n",
    "    fig_timeline = px.scatter(df, x=\"step_n\", y=\"timestamp\", color=\"Workflow\", symbol=\"lamella\",\n",
    "        # title=\"AutoLamella Timeline\", \n",
    "        hover_name=\"Workflow\", hover_data=df.columns)\n",
    "        # size = \"duration\", size_max=20)\n",
    "    return fig_timeline\n",
    "\n",
    "def generate_interaction_timeline(df: pd.DataFrame) -> go.Figure:\n",
    "\n",
    "    if len(df) == 0:\n",
    "        return None\n",
    "    \n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # convert timestamp to datetime, aus timezone \n",
    "    df.timestamp = pd.to_datetime(df.timestamp, unit=\"s\")\n",
    "\n",
    "    # convert timestamp to australian timezone\n",
    "    timezone = datetime.now().astimezone().tzinfo\n",
    "    df.timestamp = df.timestamp.dt.tz_localize(\"UTC\").dt.tz_convert(timezone)\n",
    "\n",
    "    df[\"magnitude\"] = np.sqrt(df[\"dm_x\"]**2 + df[\"dm_y\"]**2)\n",
    "\n",
    "    fig_timeline = px.scatter(df, x=\"timestamp\", y=\"magnitude\", color=\"stage\", symbol=\"type\",\n",
    "        # title=\"AutoLamella Interaction Timeline\", \n",
    "        hover_name=\"stage\", hover_data=df.columns,)\n",
    "        # size = \"duration\", size_max=20)\n",
    "\n",
    "    return fig_timeline\n",
    "\n",
    "def generate_duration_data(df: pd.DataFrame) -> Tuple[pd.DataFrame, go.Figure]:\n",
    "    df = df.copy()\n",
    "    df.rename(columns={\"petname\": \"Name\", \"stage\": \"Workflow\"}, inplace=True)\n",
    "\n",
    "    # convert duration to hr;min;sec\n",
    "    df[\"duration\"] = pd.to_timedelta(df[\"duration\"], unit='s')\n",
    "    df[\"Duration\"] = df[\"duration\"].apply(lambda x: f\"{x.components.hours:02d}:{x.components.minutes:02d}:{x.components.seconds:02d}\")\n",
    "\n",
    "    # drop Workflow in [\"Created\", \"SetupLamella\", \"Finished\"]\n",
    "    # TODO: better handling of SetupLamella\n",
    "    columns_to_drop = [\"Created\", \"PositionReady\",\"Finished\"]\n",
    "    # if \"ReadyLamella\" in df[\"Workflow\"].unique():\n",
    "        # print(\"DROPPING OLD STAGES\")\n",
    "        # columns_to_drop = [\"PreSetupLamella\", \"SetupLamella\", \"ReadyTrench\", \"Finished\"]\n",
    "    df = df[~df[\"Workflow\"].isin(columns_to_drop)]\n",
    "\n",
    "\n",
    "    fig_duration = px.bar(df, x=\"Name\", y=\"duration\", \n",
    "                        color=\"Workflow\", barmode=\"group\")\n",
    "    \n",
    "    return df[[\"Name\", \"Workflow\", \"Duration\"]], fig_duration\n",
    "\n",
    "    # # display df_experiment dataframe\n",
    "    # st.subheader(\"Experiment Data\")\n",
    "    # df_lamella = df_experiment[[\"petname\", \"current_stage\", \"failure\", \"failure_note\", \"failure_timestamp\"]].copy()\n",
    "    # # rename petname to lamella\n",
    "    # df_lamella.rename(columns={\"petname\": \"lamella\"}, inplace=True)\n",
    "    # # convert timestamp to datetime, aus timezone\n",
    "    # df_lamella.failure_timestamp = pd.to_datetime(df_lamella.failure_timestamp, unit=\"s\")\n",
    "    # st.dataframe(df_lamella)\n",
    "\n",
    "\n",
    "def generate_experiment_summary(df: pd.DataFrame) -> go.Figure:\n",
    "    pass\n",
    "\n",
    "\n",
    "def generate_report_data(filename: str, encoding: str = \"cp1252\") -> dict:\n",
    "\n",
    "    REPORT_DATA = {}\n",
    "\n",
    "    # Load experiment data\n",
    "    exp = Experiment.load(filename)\n",
    "    dfs = calculate_statistics_dataframe(exp.path, encoding=encoding)\n",
    "    df_experiment, df_history, df_beam_shift, df_steps, df_stage, df_det, df_click, df_milling = dfs\n",
    "\n",
    "    df, fig_duration = generate_duration_data(df_history)\n",
    "\n",
    "    REPORT_DATA[\"experiment_name\"] = exp.name\n",
    "    REPORT_DATA[\"experiment_summary_dataframe\"] = exp.to_summary_dataframe()\n",
    "\n",
    "    # timeline\n",
    "    REPORT_DATA[\"workflow_timeline_plot\"] = generate_workflow_timeline(df_history)\n",
    "    REPORT_DATA[\"step_timeline_plots\"] = generate_workflow_steps_timeline(df_steps)\n",
    "    # REPORT_DATA[\"step_timeline_plot\"] = generate_report_timeline(df_steps)\n",
    "    # REPORT_DATA[\"interactions_timeline_plot\"] = generate_interaction_timeline(df_click)\n",
    "\n",
    "    # duration\n",
    "    REPORT_DATA[\"duration_dataframe\"] = df\n",
    "    REPORT_DATA[\"duration_plot\"] = fig_duration\n",
    "\n",
    "    # lamella figures\n",
    "    REPORT_DATA[\"lamella_data\"] = {}\n",
    "    for p in exp.positions:\n",
    "        # figs = get_lamella_figures(p, exp.path)\n",
    "        # REPORT_DATA[\"lamella_data\"][p.name] = figs\n",
    "        REPORT_DATA[\"lamella_data\"][p.name] = \"TODO\"\n",
    "\n",
    "    return REPORT_DATA\n",
    "\n",
    "# report generation\n",
    "def generate_report(filename: str, encoding=\"utf-8\"):\n",
    "\n",
    "    report_data = generate_report_data(filename, encoding=encoding)\n",
    "\n",
    "    # Create PDF generator\n",
    "    pdf = PDFReportGenerator('autolamella.pdf')\n",
    "    \n",
    "    # Add content\n",
    "    pdf.add_title(f\"AutoLamella Report: {report_data['experiment_name']}\",\n",
    "                  f'Generated on {datetime.now().strftime(\"%B %d, %Y\")}')\n",
    "    pdf.add_paragraph('This report summarises the results of the AutoLamella experiment.')\n",
    "    pdf.add_dataframe(report_data[\"experiment_summary_dataframe\"], 'Experiment Summary')\n",
    "\n",
    "    # timeline\n",
    "    pdf.add_page_break()\n",
    "    pdf.add_plotly_figure(report_data[\"workflow_timeline_plot\"], \"Workflow Timeline\")\n",
    "    for stage_name, fig in report_data[\"step_timeline_plots\"].items():\n",
    "        pdf.add_plotly_figure(fig, f\"{stage_name} Timeline\")\n",
    "\n",
    "    # pdf.add_plotly_figure(report_data[\"interactions_timeline_plot\"], \"Interaction Timeline\")\n",
    "\n",
    "    # duration\n",
    "    # pdf.add_dataframe(report_data[\"duration_dataframe\"], 'Workflow Duration')\n",
    "    pdf.add_plotly_figure(report_data[\"duration_plot\"], \"Workflow Duration by Lamella\")\n",
    "\n",
    "    # TODO: \n",
    "    # show overall summary\n",
    "    # show overview image with positions\n",
    "    # show individual lamella data\n",
    "    # show final images for each lamella\n",
    "    # show milling patterns for each lamella\n",
    "    # show milling data\n",
    "\n",
    "    for p, figs in report_data[\"lamella_data\"].items():\n",
    "        pdf.add_page_break()\n",
    "        pdf.add_heading(f\"Lamella: {p}\")\n",
    "        # pdf.add_mpl_figure(figs[\"milling\"])\n",
    "        # pdf.add_mpl_figure(figs[\"images\"])\n",
    "        plt.close()\n",
    "\n",
    "    # Generate PDF\n",
    "    pdf.generate()\n",
    "\n",
    "generate_report(filename=filenames[2], encoding=\"cp1252\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.lib import colors\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from reportlab.lib.units import inch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image as PILImage\n",
    "import io\n",
    "\n",
    "class PDFReportGenerator:\n",
    "    def __init__(self, output_filename):\n",
    "        self.doc = SimpleDocTemplate(\n",
    "            output_filename,\n",
    "            pagesize=letter,\n",
    "            rightMargin=72,\n",
    "            leftMargin=72,\n",
    "            topMargin=72,\n",
    "            bottomMargin=72\n",
    "        )\n",
    "        self.styles = getSampleStyleSheet()\n",
    "        self.story = []\n",
    "\n",
    "    def add_array_as_heatmap(self, array, title=None, width=6, height=4, \n",
    "                            cmap='viridis', colorbar=True):\n",
    "        \"\"\"Add a numpy array as a heatmap\"\"\"\n",
    "        # Create matplotlib figure\n",
    "        fig, ax = plt.subplots(figsize=(width, height))\n",
    "        im = ax.imshow(array, cmap=cmap)\n",
    "        if colorbar:\n",
    "            plt.colorbar(im)\n",
    "        if title:\n",
    "            plt.title(title)\n",
    "        \n",
    "        # Save to bytes buffer\n",
    "        img_buffer = io.BytesIO()\n",
    "        plt.savefig(img_buffer, format='png', bbox_inches='tight', dpi=300)\n",
    "        img_buffer.seek(0)\n",
    "        plt.close()\n",
    "        \n",
    "        # Add to PDF\n",
    "        img = Image(img_buffer, width=width*inch, height=height*inch)\n",
    "        self.story.append(img)\n",
    "        self.story.append(Spacer(1, 12))\n",
    "\n",
    "    def add_array_as_image(self, array, title=None, width=6, height=4):\n",
    "        \"\"\"Add a numpy array as an image\"\"\"\n",
    "        # Convert array to PIL Image\n",
    "        if array.dtype != np.uint8:\n",
    "            # Normalize array to 0-255 range\n",
    "            array = ((array - array.min()) * (255.0 / (array.max() - array.min()))).astype(np.uint8)\n",
    "        \n",
    "        img_pil = PILImage.fromarray(array)\n",
    "        \n",
    "        # Save to bytes buffer\n",
    "        img_buffer = io.BytesIO()\n",
    "        img_pil.save(img_buffer, format='PNG')\n",
    "        img_buffer.seek(0)\n",
    "        \n",
    "        # Add to PDF\n",
    "        img = Image(img_buffer, width=width*inch, height=height*inch)\n",
    "        if title:\n",
    "            self.story.append(Paragraph(title, self.styles['Heading2']))\n",
    "        self.story.append(img)\n",
    "        self.story.append(Spacer(1, 12))\n",
    "\n",
    "    def generate(self):\n",
    "        \"\"\"Generate the PDF document\"\"\"\n",
    "        self.doc.build(self.story)\n",
    "\n",
    "# Example usage\n",
    "def example_with_arrays():\n",
    "    # Create sample arrays\n",
    "    # 1. Numeric array for heatmap\n",
    "    data_heatmap = np.random.rand(10, 10)\n",
    "    \n",
    "    # 2. Image-like array\n",
    "    x = np.linspace(0, 10, 500)\n",
    "    y = np.linspace(0, 10, 500)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    image_array = np.sin(X) * np.cos(Y)\n",
    "    \n",
    "    # Create PDF\n",
    "    pdf = PDFReportGenerator('array_visualization.pdf')\n",
    "    \n",
    "    # Add heatmap\n",
    "    pdf.add_array_as_heatmap(\n",
    "        data_heatmap, \n",
    "        title='Random Data Heatmap',\n",
    "        width=6,\n",
    "        height=4,\n",
    "        cmap='viridis'\n",
    "    )\n",
    "    \n",
    "    # Add image array\n",
    "    pdf.add_array_as_image(\n",
    "        image_array,\n",
    "        title='Sine-Cosine Pattern',\n",
    "        width=6,\n",
    "        height=4\n",
    "    )\n",
    "    \n",
    "    pdf.generate()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    example_with_arrays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Create sample data\n",
    "data = {\n",
    "    'step': ['Data Loading', 'Preprocessing', 'Analysis', 'Validation', 'Report'],\n",
    "    'timestamp': [\n",
    "        '2024-01-01 10:00:00',\n",
    "        '2024-01-01 10:30:00',\n",
    "        '2024-01-01 11:15:00',\n",
    "        '2024-01-01 13:45:00',\n",
    "        '2024-01-01 14:30:00'\n",
    "    ],\n",
    "    'duration': [1800, 2700, 9000, 2700, 3600]  # duration in seconds\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert timestamp to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Calculate end time by adding duration\n",
    "df['end_time'] = df['timestamp'] + pd.to_timedelta(df['duration'], unit='s')\n",
    "\n",
    "def plot_gantt_plotly(df):\n",
    "    \"\"\"\n",
    "    Create a Gantt chart using Plotly\n",
    "    \"\"\"\n",
    "    # Create the figure\n",
    "    fig = px.timeline(\n",
    "        df, \n",
    "        x_start='timestamp',\n",
    "        x_end='end_time',\n",
    "        y='step',\n",
    "        title='Process Timeline',\n",
    "        color='step'  # Color bars by step\n",
    "    )\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title_x=0.5,  # Center title\n",
    "        xaxis_title='Time',\n",
    "        yaxis_title='Process Step',\n",
    "        height=400,\n",
    "        showlegend=False,\n",
    "        yaxis={'categoryorder': 'total ascending'}\n",
    "    )\n",
    "\n",
    "    # Update yaxis to show all steps\n",
    "    fig.update_yaxes(autorange=\"reversed\")  # Optional: reverse order of steps\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def plot_gantt_matplotlib(df):\n",
    "    \"\"\"\n",
    "    Create a Gantt chart using Matplotlib\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Calculate duration in minutes for scaling\n",
    "    durations = (df['end_time'] - df['timestamp']).dt.total_seconds() / 60\n",
    "    \n",
    "    # Create positions for each task\n",
    "    y_positions = range(len(df))\n",
    "    \n",
    "    # Calculate start times relative to first timestamp\n",
    "    start_times = (df['timestamp'] - df['timestamp'].min()).dt.total_seconds() / 60\n",
    "    \n",
    "    # Create bars\n",
    "    ax.barh(y_positions, durations, left=start_times, height=0.3)\n",
    "    \n",
    "    # Customize chart\n",
    "    ax.set_yticks(y_positions)\n",
    "    ax.set_yticklabels(df['step'])\n",
    "    ax.invert_yaxis()  # Invert to match typical Gantt chart format\n",
    "    \n",
    "    # Add grid\n",
    "    ax.grid(True, axis='x', alpha=0.1)\n",
    "    \n",
    "    # Set title and labels\n",
    "    ax.set_title('Process Timeline')\n",
    "    ax.set_xlabel('Time (minutes from start)')\n",
    "    ax.set_ylabel('Process Step')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Example usage:\n",
    "# Plotly version\n",
    "fig_plotly = plot_gantt_plotly(df)\n",
    "# fig_plotly.show()  # Use this to display in Jupyter notebook\n",
    "\n",
    "# Matplotlib version\n",
    "fig_matplotlib = plot_gantt_matplotlib(df)\n",
    "# plt.show()  # Use this to display in Jupyter notebook\n",
    "\n",
    "# If you want to save the plots:\n",
    "# fig_plotly.write_html(\"gantt_plotly.html\")\n",
    "# fig_matplotlib.savefig(\"gantt_matplotlib.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from datetime import datetime\n",
    "\n",
    "# Create sample data with multiple pieces\n",
    "data = {\n",
    "    'piece_id': ['A1', 'A1', 'A1', 'A1', \n",
    "                 'B2', 'B2', 'B2', 'B2',\n",
    "                 'C3', 'C3', 'C3', 'C3'],\n",
    "    'step': ['Data Loading', 'Preprocessing', 'Analysis', 'Validation'] * 3,\n",
    "    'timestamp': [\n",
    "        # Piece A1\n",
    "        '2024-01-01 10:00:00', '2024-01-01 10:30:00', \n",
    "        '2024-01-01 11:15:00', '2024-01-01 13:45:00',\n",
    "        # Piece B2\n",
    "        '2024-01-01 11:00:00', '2024-01-01 11:45:00',\n",
    "        '2024-01-01 12:30:00', '2024-01-01 14:15:00',\n",
    "        # Piece C3\n",
    "        '2024-01-01 12:00:00', '2024-01-01 12:45:00',\n",
    "        '2024-01-01 13:30:00', '2024-01-01 15:15:00'\n",
    "    ],\n",
    "    'duration': [1800, 2700, 9000, 2700] * 3  # duration in seconds\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert timestamp to datetime and calculate end time\n",
    "df['start_time'] = pd.to_datetime(df['timestamp'])\n",
    "df['end_time'] = df['start_time'] + pd.to_timedelta(df['duration'], unit='s')\n",
    "\n",
    "# Create two different views\n",
    "fig1 = plot_multi_gantt(df, color_by='piece_id', barmode='group')\n",
    "fig2 = plot_multi_gantt(df, color_by='piece_id', barmode='overlay')\n",
    "\n",
    "# Optional: Add custom hover template\n",
    "fig1.update_traces(\n",
    "    hovertemplate=\"<br>\".join([\n",
    "        \"Piece: %{customdata[0]}\",\n",
    "        \"Step: %{y}\",\n",
    "        \"Start: %{x[0]}\",\n",
    "        \"End: %{x[1]}\",\n",
    "        \"<extra></extra>\"\n",
    "    ]),\n",
    "    customdata=df[['piece_id']]\n",
    ")\n",
    "\n",
    "fig1.show()\n",
    "fig2.show()\n",
    "\n",
    "# If you want to save the plots:\n",
    "fig1.write_html(\"gantt_grouped.html\")\n",
    "fig2.write_html(\"gantt_overlay.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = \"/home/patrick/data/monash-cryo-em/AutoLamella-Exports/autolamella/20241022_Sai/AutoLamella-2024-10-22-09-37/history.csv\"\n",
    "# CSV_PATH = \"/home/patrick/github/autolamella/autolamella/log/AutoLamella-2025-01-10-14-24/history.csv\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "display(df)\n",
    "\n",
    "# fig = generate_workflow_timeline(df)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "CSV_PATH = \"/home/patrick/data/monash-cryo-em/AutoLamella-Exports/autolamella/20241022_Sai/AutoLamella-2024-10-22-09-37steps.csv\"\n",
    "# CSV_PATH = \"/home/patrick/github/autolamella/autolamella/log/AutoLamella-2025-01-10-14-24/history.csv\"\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "workflow_steps_figures = generate_workflow_steps_timeline(df)\n",
    "\n",
    "for k, v in workflow_steps_figures.items():\n",
    "    print(f\"WORKFLOW: {k}\")\n",
    "    v.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "PATH = \"/home/patrick/data/monash-cryo-em/AutoLamella-Exports/autolamella/20241022_Sai/AutoLamella-2024-10-22-09-37\"\n",
    "# PATH = \"/home/patrick/github/autolamella/autolamella/log/AutoLamella-2025-01-10-14-24\"\n",
    "\n",
    "# from autolamella.tools.data import calculate_statistics_dataframe\n",
    "from autolamella.structures import Experiment\n",
    "\n",
    "dfs = calculate_statistics_dataframe(PATH, encoding=\"utf-8\")\n",
    "exp = Experiment.load(f\"{PATH}/experiment.yaml\")\n",
    "protocol = AutoLamellaProtocol.load(f\"{PATH}/protocol.yaml\")\n",
    "\n",
    "# display(exp.to_dataframe_v2())\n",
    "# df = exp.to_summary_dataframe()\n",
    "# display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autolamella.structures import AutoLamellaStage\n",
    "from fibsem.milling.patterning.plotting import draw_milling_patterns\n",
    "from fibsem.milling import get_milling_stages\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from fibsem.structures import FibsemImage\n",
    "from autolamella.protocol.validation import convert_old_milling_protocol_to_new_protocol, MILL_POLISHING_KEY, MILL_ROUGH_KEY, MICROEXPANSION_KEY, FIDUCIAL_KEY\n",
    "PATH = \"/home/patrick/data/monash-cryo-em/AutoLamella-Exports/autolamella/20241022_Sai/AutoLamella-2024-10-22-09-37\"\n",
    "# PATH = \"/home/patrick/github/autolamella/autolamella/log/AutoLamella-2025-01-10-14-24\"\n",
    "\n",
    "exp = Experiment.load(f\"{PATH}/experiment.yaml\")\n",
    "\n",
    "print(f\"Total Lamella: {len(exp.positions)}, Finished Lamella: {len(exp.at_stage(AutoLamellaStage.Finished))})\")\n",
    "failed_lamella = exp.at_failure()\n",
    "print(f\"Failed Lamella: {[l.name for l in failed_lamella]}\")\n",
    "\n",
    "\n",
    "for p in exp.positions:\n",
    "    print(p.name)\n",
    "\n",
    "    # replace keys in protocol\n",
    "    # MillRoughCut -> MILL_ROUGH_KEY\n",
    "    # MillPolishingCut -> MILL_POLISHING_KEY\n",
    "    # remove lamella\n",
    "\n",
    "    figures = get_lamella_figures(p)\n",
    "    plt.show()\n",
    "    \n",
    "    # if figures is not None:\n",
    "        # figures[\"milling\"].show()\n",
    "        # figures[\"images\"].show()\n",
    "\n",
    "\n",
    "# # drop spacing, rate, preset, spot_size #Tescan only\n",
    "# TESCAN_PARAMS = [\"spacing\", \"rate\", \"preset\", \"spot_size\"]\n",
    "# df = df.drop(columns=TESCAN_PARAMS)\n",
    "\n",
    "# # filter to WorkflowStage == \"MillRough\", \"MillPolishing\", fiducial\n",
    "# milling_workflows = [\"MillRoughCut\", \"MillPolishingCUt\", \"microexpansion\", \"fiducial\"]\n",
    "# df = df[df[\"WorkflowStage\"].isin(milling_workflows)]\n",
    "\n",
    "# # filter to only milling_current, voltage, depth\n",
    "# df = df[[\"Experiment\", \"Lamella\", \"WorkflowStage\", \"MillingStage\", \n",
    "#             \"type\", \"milling_current\", \"milling_voltage\", \"depth\", \"lamella_height\", \"lamella_width\", \"height\", \"width\"]]\n",
    "# display(df)\n",
    "\n",
    "# # save to csv at exp.path \"milling.csv\"\n",
    "# df.to_csv(os.path.join(exp.path, \"protocol.csv\"), index=False)\n",
    "\n",
    "# # continue\n",
    "# for pos in exp.positions:\n",
    "    \n",
    "#     if not pos.is_failure:\n",
    "#         continue\n",
    "#     print(f\"{pos.name}: {pos.failure_note}\")\n",
    "    \n",
    "#     # load milling stages\n",
    "#     protocol = pos.protocol\n",
    "#     milling_stages = []\n",
    "#     for mw in milling_workflows:\n",
    "#         stages = get_milling_stages(key=mw, protocol=protocol, point=Point.from_dict(protocol[mw][\"point\"]))\n",
    "#         milling_stages.extend(stages)\n",
    "\n",
    "#     # TODO: lamella path is not correct when re-loaded on another machine\n",
    "#     fib_image = FibsemImage.load(os.path.join(exp.path, pos.name, \"ref_MillPolishingCut_final_high_res_ib.tif\"))\n",
    "#     sem_image = FibsemImage.load(os.path.join(exp.path, pos.name, \"ref_MillPolishingCut_final_high_res_eb.tif\"))\n",
    "\n",
    "#     fig, ax1 = draw_milling_patterns(fib_image, milling_stages)\n",
    "#     plt.title(pos.name)\n",
    "#     plt.show()\n",
    "\n",
    "#     fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "#     ax[0].imshow(sem_image.data, cmap=\"gray\")\n",
    "#     ax[1].imshow(fib_image.data, cmap=\"gray\")\n",
    "\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autolamella.structures import AutoLamellaStage\n",
    "from fibsem.milling.patterning.plotting import draw_milling_patterns\n",
    "from fibsem.milling import get_milling_stages\n",
    "\n",
    "for filename in filenames:\n",
    "    experiment_path = os.path.dirname(filename)\n",
    "    print(f\"Experiment: {experiment_path}\")\n",
    "\n",
    "    try:\n",
    "\n",
    "            print(\"-\"*80)\n",
    "            continue\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fibsem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
